{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8e45331b802485991b70655ced06a8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oana/PycharmProjects/midjourney-4-style/venv/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/Users/oana/PycharmProjects/midjourney-4-style/venv/lib/python3.9/site-packages/diffusers/loaders/lora.py:708: FutureWarning: `_modify_text_encoder` is deprecated and will be removed in version 0.25. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n",
      "  deprecate(\"_modify_text_encoder\", \"0.25\", LORA_DEPRECATION_MESSAGE)\n",
      "/Users/oana/PycharmProjects/midjourney-4-style/venv/lib/python3.9/site-packages/diffusers/loaders/lora.py:679: FutureWarning: `_remove_text_encoder_monkey_patch_classmethod` is deprecated and will be removed in version 0.25. You are using an old version of LoRA backend. This will be deprecated in the next releases in favor of PEFT make sure to install the latest PEFT and transformers packages in the future.\n",
      "  deprecate(\"_remove_text_encoder_monkey_patch_classmethod\", \"0.25\", LORA_DEPRECATION_MESSAGE)\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"Lykon/dreamshaper-7\", torch_dtype=torch.float16, use_safetensors=True)\n",
    "pipeline.load_lora_weights(\"openskyml/midjourney-v4-xl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:06:45.666129Z",
     "start_time": "2023-11-30T22:06:37.242635Z"
    }
   },
   "id": "bc2a9cac6f0fbcdc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "prompt = \"RTX, UNREAL ENGINE, Global illumination, Deep glow, Particles Highly detailed painting image quality of The kiss passion beautiful woman with long hair and blue dress and knite unreal engine, fantasy art by greg rutkowski, loish, rhads, ferdinand knab, makoto shinkai and lois van baarle, ilya kuvshinov, rossdraws, tom bagshaw, global illumination, radiant light, detailed and intricate environment \"\n",
    "def get_inputs(batch_size=1):\n",
    "    prompts = batch_size * [prompt]\n",
    "    num_inference_steps = 50\n",
    "\n",
    "    return {\"prompt\": prompts, \"num_inference_steps\": num_inference_steps}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:09:07.892732Z",
     "start_time": "2023-11-30T22:09:07.887488Z"
    }
   },
   "id": "fa6e1e4fb2363bd"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def dummy(images, **kwargs):\n",
    "    return images, [False]\n",
    "pipeline.safety_checker = dummy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T22:13:29.207176Z",
     "start_time": "2023-11-30T22:13:29.198966Z"
    }
   },
   "id": "9ba01799f2311d27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['shaw, global illumination, radiant light, detailed and intricate environment']\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47f6caeafabb44f0a2ee499a67629ab0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers.utils import make_image_grid\n",
    "pipeline.to('mps')\n",
    "pipeline.enable_attention_slicing()\n",
    "images = pipeline(**get_inputs(batch_size=1), max_embeddings_multiples=3).images\n",
    "images[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T22:13:31.789189Z"
    }
   },
   "id": "417284f5c4a5b447"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6466b492278c2438"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
